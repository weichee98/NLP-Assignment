{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zytan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\zytan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sentence_tokenizer = PunktSentenceTokenizer()\n",
    "def tokenize_word(s):\n",
    "    return [word for word in word_tokenize(s) if any(char.isalpha() or char.isdigit() for char in word)]\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_texts = dict()\n",
    "\n",
    "def remove(text, tag):\n",
    "    front = \"<\" + tag + \">\"\n",
    "    end = \"</\" + tag + \">\"\n",
    "    return text.replace(front, \"\").replace(end, \"\")    \n",
    "\n",
    "# Read the XML file\n",
    "for filename in glob.glob('Dataset/chemistry/*.xml'):\n",
    "    all_paragraphs = list()\n",
    "    with open(filename, \"r\") as f:\n",
    "        # Read each line in the file, readlines() returns a list of lines\n",
    "        content = f.read()\n",
    "        content = remove(content, \"sup\")\n",
    "        content = remove(content, \"sub\")\n",
    "        content = remove(content, \"italic\")\n",
    "        content = remove(content, \"bold\")\n",
    "        soup = bs(content, 'html.parser')\n",
    "        for p in soup.find_all('p'):\n",
    "            paragraph = p.get_text(' ').replace('\\u2009', ' ')\n",
    "            all_paragraphs.append(paragraph)\n",
    "    chemistry_texts[filename] = \"\\n\".join(all_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemistry_sentences = {k: sentence_tokenizer.tokenize(v) for k, v in chemistry_texts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High-speed countercurrent chromatography (HSCCC) is a new type of liquid–liquid partition chromatography technology.',\n",
       " 'For the adsorption of CR and SF, the thermodynamic parameters (∆G°, ∆H°, ∆S°) were determined using the Van’t Hoff equation.',\n",
       " 'The nitrogen atom of imine (-C=N-) Schiff base group is thought to involve in hydrogen bonding with several cellular constituents [ 15 ] which can modulate activities and processes.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose Sentences\n",
    "chemistry_choosen = [\n",
    "    chemistry_sentences['Dataset/chemistry\\\\1234269.xml'][114],\n",
    "    chemistry_sentences['Dataset/chemistry\\\\7617989.xml'][217],\n",
    "    chemistry_sentences['Dataset/chemistry\\\\3928204.xml'][18]\n",
    "]\n",
    "chemistry_choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-speed/JJ countercurrent/NN chromatography/NN HSCCC/NNP is/VBZ a/DT new/JJ type/NN of/IN liquid–liquid/JJ partition/NN chromatography/NN technology/NN\n",
      "For/IN the/DT adsorption/NN of/IN CR/NNP and/CC SF/NNP the/DT thermodynamic/JJ parameters/NNS ∆G°/VBP ∆H°/JJ ∆S°/NNS were/VBD determined/VBN using/VBG the/DT Van/NNP t/NN Hoff/NNP equation/NN\n",
      "The/DT nitrogen/NN atom/NN of/IN imine/JJ -C=N-/NNP Schiff/NNP base/NN group/NN is/VBZ thought/VBN to/TO involve/VB in/IN hydrogen/NN bonding/NN with/IN several/JJ cellular/JJ constituents/NNS 15/CD which/WDT can/MD modulate/VB activities/NNS and/CC processes/NNS\n"
     ]
    }
   ],
   "source": [
    "chemistry_tag = [pos_tag(tokenize_word(s)) for s in chemistry_choosen]\n",
    "\n",
    "for s in chemistry_tag:\n",
    "    print(\" \".join([\"/\".join(tag) for tag in s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_texts = dict()\n",
    "\n",
    "# Read the XML files\n",
    "for filename in glob.glob('Dataset/legal/*.xml'):\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()\n",
    "        soup = bs(content, 'html.parser')\n",
    "        legal_texts[filename] = soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_sentences = {k: sentence_tokenizer.tokenize(v) for k, v in legal_texts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wilcox J made orders ancillary to the Mareva orders on 22 March 2005 requiring each of the Sharman applicants to disclose on affidavit the description and value of all of their assets, wherever situated, and to specify whether those assets were held by each applicant either beneficially or in trust for any other person or entity.',\n",
       " \"The 1994 Award is an award made by the Australian Industrial Relations Commission ('the Commission'), pursuant to the Industrial Relations Act 1988 (Cth), which subsequently became the WR Act.\",\n",
       " 'The first respondent proposes to put a logo on the façade of the store above the entrance which displays the words \"Oasis Foam & Rubber\" against a light blue or aqua background to the word \"Oasis\".']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose Sentences\n",
    "legal_choosen = [\n",
    "    legal_sentences['Dataset/legal\\\\06_1.xml'][3],\n",
    "    legal_sentences['Dataset/legal\\\\06_11.xml'][12],\n",
    "    legal_sentences['Dataset/legal\\\\06_15.xml'][20]\n",
    "]\n",
    "legal_choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcox/NNP J/NNP made/VBD orders/NNS ancillary/JJ to/TO the/DT Mareva/NNP orders/NNS on/IN 22/CD March/NNP 2005/CD requiring/VBG each/DT of/IN the/DT Sharman/NNP applicants/NNS to/TO disclose/VB on/IN affidavit/NN the/DT description/NN and/CC value/NN of/IN all/DT of/IN their/PRP$ assets/NNS wherever/RB situated/VBN and/CC to/TO specify/VB whether/IN those/DT assets/NNS were/VBD held/VBN by/IN each/DT applicant/NN either/CC beneficially/RB or/CC in/IN trust/NN for/IN any/DT other/JJ person/NN or/CC entity/NN\n",
      "The/DT 1994/CD Award/NNP is/VBZ an/DT award/NN made/VBN by/IN the/DT Australian/JJ Industrial/NNP Relations/NNPS Commission/NNP 'the/POS Commission/NNP pursuant/NN to/TO the/DT Industrial/NNP Relations/NNP Act/NNP 1988/CD Cth/NNP which/WDT subsequently/RB became/VBD the/DT WR/NNP Act/NNP\n",
      "The/DT first/JJ respondent/NN proposes/VBZ to/TO put/VB a/DT logo/NN on/IN the/DT façade/NN of/IN the/DT store/NN above/IN the/DT entrance/NN which/WDT displays/VBZ the/DT words/NNS Oasis/NNP Foam/NNP Rubber/NNP against/IN a/DT light/JJ blue/NN or/CC aqua/NN background/NN to/TO the/DT word/NN Oasis/NN\n"
     ]
    }
   ],
   "source": [
    "legal_tag = [pos_tag(tokenize_word(s)) for s in legal_choosen]\n",
    "\n",
    "for s in legal_tag:\n",
    "    print(\" \".join([\"/\".join(tag) for tag in s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dataset/sports.txt', 'r', encoding='utf-8') as f:\n",
    "    sports_texts = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_sentences = sentence_tokenizer.tokenize(sports_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yet Howard still possesses one of the more powerful strokes in the league, evidenced by 14 homers in 71 games, and his 27.5 home-run-to-fly-ball percentage was his best showing since 2008.',\n",
       " \"For her eighth birthday, 10 days before the league's first game, her uncle gave her a pair of regulation-size WNBA basketballs, one outdoor, one indoor.\",\n",
       " 'Suppose their remains suspicion from Dunn’s infamous 2011 output (.159/.292/.277 in 122 games), yet the Windy City slugger’s rushed return from an early-season emergency appendectomy was probably the catalyst for this lethargic showing.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose Sentences\n",
    "sports_choosen = [\n",
    "    sports_sentences[126],\n",
    "    sports_sentences[1742],\n",
    "    sports_sentences[141]\n",
    "]\n",
    "sports_choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yet/RB Howard/NNP still/RB possesses/VBZ one/CD of/IN the/DT more/RBR powerful/JJ strokes/NNS in/IN the/DT league/NN evidenced/VBN by/IN 14/CD homers/NNS in/IN 71/CD games/NNS and/CC his/PRP$ 27.5/CD home-run-to-fly-ball/JJ percentage/NN was/VBD his/PRP$ best/JJS showing/NN since/IN 2008/CD\n",
      "For/IN her/PRP$ eighth/JJ birthday/JJ 10/CD days/NNS before/IN the/DT league/NN 's/POS first/JJ game/NN her/PRP$ uncle/NN gave/VBD her/PRP a/DT pair/NN of/IN regulation-size/JJ WNBA/NNP basketballs/VBZ one/CD outdoor/NN one/CD indoor/NN\n",
      "Suppose/VB their/PRP$ remains/NNS suspicion/NN from/IN Dunn/NNP s/RB infamous/JJ 2011/CD output/NN .159/.292/.277/NNP in/IN 122/CD games/NNS yet/RB the/DT Windy/NNP City/NNP slugger/NN s/NN rushed/VBD return/NN from/IN an/DT early-season/JJ emergency/NN appendectomy/NN was/VBD probably/RB the/DT catalyst/NN for/IN this/DT lethargic/JJ showing/NN\n"
     ]
    }
   ],
   "source": [
    "sports_tag = [pos_tag(tokenize_word(s)) for s in sports_choosen]\n",
    "\n",
    "for s in sports_tag:\n",
    "    print(\" \".join([\"/\".join(tag) for tag in s]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
